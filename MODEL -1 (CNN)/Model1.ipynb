{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNNfinal-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2pxbSvIWF_H"
      },
      "source": [
        "# Import the Libraries : \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import Input\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, add,Dropout,Dense,Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from numpy import save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC9E_DAojOQp",
        "outputId": "c08fe66d-f5da-436c-adbe-ba583648426d"
      },
      "source": [
        "# Load the data set to the Google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwl1bjNLyQhc"
      },
      "source": [
        "# we pass the data set into different pakages\n",
        "mini_batch_size = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehBhwF_4_ua",
        "outputId": "f5d0b1df-e467-4c11-ba16-563918c7745f"
      },
      "source": [
        "Y=np.load('/content/drive/MyDrive/Unrar/Yfinal.npy')\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35679, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dcWsIXb5EdG",
        "outputId": "9bd683c5-4c48-4661-d7d1-e6945da3f263"
      },
      "source": [
        "X=np.load('/content/drive/MyDrive/Unrar/Xfinal.npy')\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35679, 38, 1, 252)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl5WAdtVdQ7q",
        "outputId": "528f5555-f001-4529-d6af-1edc85837632"
      },
      "source": [
        "X=X[:Y.shape[0],:]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35679, 38, 1, 252)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnTRxph_j0au"
      },
      "source": [
        "# Dividing the data in train, test and validation\n",
        "# 20% data in test_size , 20% in validation_set and rest in test_set\n",
        "from sklearn.model_selection import train_test_split\n",
        "test_size = 0.2\n",
        "validation_size = 0.2\n",
        "\n",
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=test_size)\n",
        "    \n",
        "# create train validation split\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EkumxNQT9g",
        "outputId": "cbce39e8-427d-4104-d0e8-91b6e7c87c06"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35679, 38, 1, 252)\n",
            "(35679, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WHpSdposTkJ",
        "outputId": "854ab514-cc90-4492-e497-b1618666b0c8"
      },
      "source": [
        "# The X_train is converted to 4 dimension with a mini_batch size of 400 \n",
        "X_train = X_train[:int(X_train.shape[0]/mini_batch_size)*mini_batch_size,:]\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22800, 38, 1, 252)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKiU1ADOsUbB",
        "outputId": "05401099-3a45-4f28-c1a2-dd18a5d404d5"
      },
      "source": [
        "# The Y_train is converted to 4 dimension with a mini_batch size of 400 similar to X_train\n",
        "y_train = y_train[:int(y_train.shape[0]/mini_batch_size)*mini_batch_size,:]\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22800, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z5TfRCPkA_t",
        "outputId": "c366c11c-423d-4932-cdbc-9eb92e3f9d60"
      },
      "source": [
        "# Shapes of both X_train and y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22800, 38, 1, 252)\n",
            "(22800, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwtDTlgaJEAn",
        "outputId": "16cc07bb-76ae-4d19-cf21-8cd6f80929ae"
      },
      "source": [
        "# shape of validation set :\n",
        "print(X_validation.shape)\n",
        "print(y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5709, 38, 1, 252)\n",
            "(5709, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2o0MejnF11s",
        "outputId": "b4d4ed2c-12a4-4c50-8455-671880e3d33b"
      },
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7136, 38, 1, 252)\n",
            "(7136, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdwSG7TUj5tw"
      },
      "source": [
        "# preparing test and validation data\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "train_data = train_data.batch(mini_batch_size)\n",
        "\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_validation,y_validation))\n",
        "validation_data = validation_data.batch(mini_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxZrSgJ_dh1T",
        "outputId": "3a147611-16eb-496f-ba20-3c43fd76bda1"
      },
      "source": [
        "print(train_data)\n",
        "print(validation_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 38, 1, 252), (None, 38, 1, 88)), types: (tf.float64, tf.float64)>\n",
            "<BatchDataset shapes: ((None, 38, 1, 252), (None, 38, 1, 88)), types: (tf.float64, tf.float64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlRDYMOXvBB8"
      },
      "source": [
        "# parameters for the layers of neural network \n",
        "window_size=7\n",
        "min_midi = 21\n",
        "max_midi = 108\n",
        "note_range = max_midi - min_midi + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6YkMthtTE4i"
      },
      "source": [
        "# layers of Model \n",
        "input_shape=(None,38,1,252) #number of samples\n",
        "model=Sequential()\n",
        "\n",
        "# 1st Layer \n",
        "model.add(Conv2D(filters=32, kernel_size=(5,4),padding=\"same\", activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "# 2nd Layer \n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3),padding=\"same\", activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(MaxPool2D(pool_size=(1, 2),padding=\"same\"))\n",
        "\n",
        "#stage3\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# 4th Layer \n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(88, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYyqPWpNbxhF"
      },
      "source": [
        "# Code for the Accuracy of the Model \n",
        "class AccuracyHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.acc = []\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.acc.append(logs.get('acc'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhVKImwVbo_2"
      },
      "source": [
        "# Calculating the accuracy of the model using adam as optimizer and the learning rate is 0.001\n",
        "optimizer1 = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizer1, metrics=['accuracy'])\n",
        "history = AccuracyHistory()\n",
        "\n",
        "# checkpoint = ModelCheckpoint(model_ckpt,monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n",
        "early_stop = EarlyStopping(patience=5, monitor='val_loss',verbose=1, mode='min')\n",
        "callbacks = [history,early_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r-7rgbykCNm",
        "outputId": "b264fbcf-8983-4b2e-988c-0ddc7ec94ecd"
      },
      "source": [
        "model.fit(train_data,epochs=10,batch_size=mini_batch_size,validation_data=validation_data, verbose = 1, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 38s 106ms/step - loss: 0.6689 - accuracy: 0.0196 - val_loss: 0.4911 - val_accuracy: 0.0236\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 6s 102ms/step - loss: 0.3152 - accuracy: 0.0337 - val_loss: 0.2069 - val_accuracy: 0.0357\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 6s 102ms/step - loss: 0.1907 - accuracy: 0.0329 - val_loss: 0.1835 - val_accuracy: 0.0275\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 6s 102ms/step - loss: 0.1750 - accuracy: 0.0473 - val_loss: 0.1767 - val_accuracy: 0.0369\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 0.1637 - accuracy: 0.0789 - val_loss: 0.1654 - val_accuracy: 0.0718\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 6s 102ms/step - loss: 0.1528 - accuracy: 0.1033 - val_loss: 0.1514 - val_accuracy: 0.1056\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 6s 107ms/step - loss: 0.1447 - accuracy: 0.1165 - val_loss: 0.1403 - val_accuracy: 0.1267\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 6s 109ms/step - loss: 0.1397 - accuracy: 0.1292 - val_loss: 0.1314 - val_accuracy: 0.1436\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 0.1361 - accuracy: 0.1379 - val_loss: 0.1271 - val_accuracy: 0.1626\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 6s 111ms/step - loss: 0.1335 - accuracy: 0.1478 - val_loss: 0.1226 - val_accuracy: 0.1697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25000932d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-ON-d7okDY6",
        "outputId": "b25de1d6-52ef-4135-a509-1c6ae6280f26"
      },
      "source": [
        "# Summary of the Model and dimension of different layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper (ModuleWrappe (None, 38, 1, 32)         161312    \n",
            "_________________________________________________________________\n",
            "module_wrapper_1 (ModuleWrap (None, 38, 1, 32)         128       \n",
            "_________________________________________________________________\n",
            "module_wrapper_2 (ModuleWrap (None, 38, 1, 32)         0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_3 (ModuleWrap (None, 38, 1, 32)         9248      \n",
            "_________________________________________________________________\n",
            "module_wrapper_4 (ModuleWrap (None, 38, 1, 32)         128       \n",
            "_________________________________________________________________\n",
            "module_wrapper_5 (ModuleWrap (None, 38, 1, 32)         0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_6 (ModuleWrap (None, 38, 1, 32)         0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_7 (ModuleWrap (None, 38, 1, 1000)       33000     \n",
            "_________________________________________________________________\n",
            "module_wrapper_8 (ModuleWrap (None, 38, 1, 1000)       4000      \n",
            "_________________________________________________________________\n",
            "module_wrapper_9 (ModuleWrap (None, 38, 1, 1000)       0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_10 (ModuleWra (None, 38, 1, 200)        200200    \n",
            "_________________________________________________________________\n",
            "module_wrapper_11 (ModuleWra (None, 38, 1, 200)        800       \n",
            "_________________________________________________________________\n",
            "module_wrapper_12 (ModuleWra (None, 38, 1, 200)        0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_13 (ModuleWra (None, 38, 1, 88)         17688     \n",
            "=================================================================\n",
            "Total params: 426,504\n",
            "Trainable params: 423,976\n",
            "Non-trainable params: 2,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073WSrX1Hjeb",
        "outputId": "51ede509-d5e0-4cd9-e66c-8a55ec8377d3"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(score)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.12075378000736237, 0.17266418039798737]\n",
            "Test loss: 0.12075378000736237\n",
            "Test accuracy:  0.17266418039798737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxhB1jTTJiWS"
      },
      "source": [
        "y_true=y_validation\n",
        "y_scores=model.predict(X_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJRwmCAU6uEd"
      },
      "source": [
        "def opt_thresholds(y_true,y_scores):\n",
        "    othresholds = np.zeros(y_scores.shape[1])\n",
        "    print(othresholds.shape)\n",
        "    for label, (label_scores, true_bin) in enumerate(zip(y_scores.T,y_true.T)):\n",
        "        precision, recall, thresholds = sklearn.metrics.precision_recall_curve(true_bin, label_scores)\n",
        "        max_f1 = 0\n",
        "        max_f1_threshold = .5\n",
        "        for r, p, t in zip(recall, precision, thresholds):\n",
        "            if p + r == 0: continue\n",
        "            if (2*p*r)/(p + r) > max_f1:\n",
        "                max_f1 = (2*p*r)/(p + r)\n",
        "                max_f1_threshold = t\n",
        "        # print(\"label %f: max_f1_threshold %f => max_f1 %f\" %(label, max_f1_threshold, max_f1))\n",
        "        othresholds[label] = max_f1_threshold\n",
        "        # print(othresholds)\n",
        "    return othresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGwlcnb5rB9",
        "outputId": "64ad8339-fd5b-4a87-a6cf-f794f7b17b2e"
      },
      "source": [
        "#calculating threshold on validation data\n",
        "x, y_true=X_validation, y_validation\n",
        "y_scores=model.predict(x)\n",
        "y_scores=np.reshape(y_scores, (216942, 88))\n",
        "y_validation=np.reshape(y_validation, (216942, 88))\n",
        "othresholds = opt_thresholds(y_true,y_scores)\n",
        "\n",
        "#evaludate this over validation data\n",
        "y_pred = y_scores > othresholds\n",
        "#precision, recall, fbetascore, support =>p, r, f, s\n",
        "p,r,f,s = sklearn.metrics.precision_recall_fscore_support(y_true,y_pred,average='micro')\n",
        "print(\"%f %f %f\" %(p, r, f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.417107 0.628845 0.501544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq1JXV0YaGew"
      },
      "source": [
        "y_scores_test=model.predict(X_test)\n",
        "#evaludate this over test data so that we get a 4D boolean matrix\n",
        "y_pred_test = y_scores_test > othresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0W-RjH6cQJh",
        "outputId": "55b5c647-008d-43c5-9f84-953129b4d0f7"
      },
      "source": [
        "print(y_pred_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7136, 38, 1, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8tpJvqcd4M",
        "outputId": "1a31113b-84c9-4bfd-eea6-4b52ef7bffe0"
      },
      "source": [
        "print(y_pred_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]\n",
            "\n",
            "\n",
            " [[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]\n",
            "\n",
            "\n",
            " [[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]\n",
            "\n",
            "\n",
            " [[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]\n",
            "\n",
            "\n",
            " [[[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]\n",
            "\n",
            "  [[False False False ... False False False]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFwO_VKIBY3-",
        "outputId": "15a32787-e474-4bf0-c69c-4a00888436b4"
      },
      "source": [
        "print(othresholds.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8J52hGGc_Jo",
        "outputId": "274d594c-af8e-4696-c088-78fcea8c008d"
      },
      "source": [
        "y_pred_test=np.squeeze(y_pred_test, axis=-2)\n",
        "print(y_pred_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7136, 38, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW2i63GxoYdy"
      },
      "source": [
        "#saving the y_pred_test for further post processing and generating piano roll\n",
        "save('final2.npy', y_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}